{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f6hYNIvWpyuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f53b2d-c62d-4a28-8175-e77e3de467eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m126.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit pyngrok google-generativeai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "Zc2tMvsMp2oN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"AIzaSyAJWTJU0ZQBOhzTd1eWeWNxmnVcLLC_8f0\" # eta amr api kintu :3\n",
        "genai.configure(api_key=API_KEY)\n",
        "model = genai.GenerativeModel(\"gemini-2.5-flash\")"
      ],
      "metadata": {
        "id": "djqb12CRqHxj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 30SgnpBDdy6Mx8r3iI5CVJAKvew_33mfURpPUu5wRgDJdX9WM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsD0DUI7rTx9",
        "outputId": "069fa797-e95e-4251-b0ec-88f7d7daa69d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "ngrok.kill()\n",
        "print(\"Starting Streamlit app...\")\n",
        "streamlit_proc = subprocess.Popen([\"streamlit\", \"run\", \"app.py\"])\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"ğŸŒ Open this Streamlit app link:\\n{public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5wkykU5rXBT",
        "outputId": "f96b1148-218c-496d-e79a-c58443e2e5bf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Streamlit app...\n",
            "ğŸŒ Open this Streamlit app link:\n",
            "NgrokTunnel: \"https://512f33b1a89a.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile app.py\n",
        "import os\n",
        "import re\n",
        "import ast\n",
        "import math\n",
        "import json\n",
        "import tempfile\n",
        "from typing import Optional, Dict, List, Tuple\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "# Optional third-party packages\n",
        "try:\n",
        "    import sacrebleu\n",
        "except Exception:\n",
        "    sacrebleu = None\n",
        "\n",
        "# Try Groq client import\n",
        "try:\n",
        "    from groq import Groq\n",
        "except Exception:\n",
        "    Groq = None\n",
        "\n",
        "try:\n",
        "    import openai\n",
        "except Exception:\n",
        "    openai = None\n",
        "\n",
        "# ---------------------------\n",
        "# Utilities\n",
        "# ---------------------------\n",
        "\n",
        "def extract_code_only(text: str) -> str:\n",
        "    \"\"\"Strip markdown fences and assistant lead-ins and return the largest code block if present.\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "\n",
        "    fences = re.findall(r\"```(?:[\\w+-]*)\\n(.*?)```\", text, re.DOTALL)\n",
        "    if fences:\n",
        "        fences_sorted = sorted(fences, key=lambda s: len(s), reverse=True)\n",
        "        return fences_sorted[0].strip()\n",
        "\n",
        "    lines = text.strip().splitlines()\n",
        "    leadin_pattern = re.compile(r\"^(here(?:'s| is)|sure|okay|note|the following)[:\\-â€”\\s]\", re.I)\n",
        "    while lines and leadin_pattern.match(lines[0].strip()):\n",
        "        lines.pop(0)\n",
        "    return \"\\n\".join(lines).strip()\n",
        "\n",
        "# ---------------------------\n",
        "# Code generation agent\n",
        "# ---------------------------\n",
        "class CodeGenAgent:\n",
        "    def __init__(self, groq_api_key: Optional[str] = None, openai_api_key: Optional[str] = None, temperature: float = 0.0):\n",
        "        self.groq_api_key = groq_api_key or os.getenv(\"GROQ_API_KEY\")\n",
        "        self.openai_api_key = openai_api_key or os.getenv(\"OPENAI_API_KEY\")\n",
        "        self.temperature = temperature\n",
        "        self._groq_client = None\n",
        "\n",
        "    def _init_groq(self):\n",
        "        if Groq is None:\n",
        "            raise RuntimeError(\"Groq SDK not available. Install it or use OpenAI fallback.\")\n",
        "        if self._groq_client is None:\n",
        "            try:\n",
        "                self._groq_client = Groq(api_key=self.groq_api_key) if self.groq_api_key else Groq()\n",
        "            except Exception:\n",
        "                self._groq_client = Groq()\n",
        "        return self._groq_client\n",
        "\n",
        "    def _call_groq(self, prompt: str, model: str, max_tokens: int = 2000) -> str:\n",
        "        client = self._init_groq()\n",
        "        # Adapt to SDK shapes; try common patterns.\n",
        "        try:\n",
        "            resp = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You MUST return only the requested source code. No explanations, no markdown fences.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=self.temperature,\n",
        "                max_tokens=max_tokens,\n",
        "            )\n",
        "            return resp.choices[0].message.content\n",
        "        except Exception:\n",
        "            # Try alternate call shape\n",
        "            resp = client.create_chat_completion(model=model, messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You MUST return only the requested source code. No explanations, no markdown fences.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ], temperature=self.temperature)\n",
        "            return resp.choices[0].message.content\n",
        "\n",
        "    def _call_openai(self, prompt: str, model: str = \"gpt-4o-mini\", max_tokens: int = 2000) -> str:\n",
        "        if openai is None:\n",
        "            raise RuntimeError(\"OpenAI Python package not installed.\")\n",
        "        openai.api_key = self.openai_api_key\n",
        "        # Attempt ChatCompletion usage\n",
        "        try:\n",
        "            resp = openai.ChatCompletion.create(\n",
        "                model=model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You MUST return only the requested source code. No explanations, no markdown fences.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=self.temperature,\n",
        "                max_tokens=max_tokens,\n",
        "            )\n",
        "            return resp.choices[0].message.content\n",
        "        except Exception:\n",
        "            # Try newer client shapes if present\n",
        "            try:\n",
        "                resp = openai.chat.completions.create(model=model, messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You MUST return only the requested source code. No explanations, no markdown fences.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ], temperature=self.temperature)\n",
        "                return resp.choices[0].message.content\n",
        "            except Exception as e:\n",
        "                raise\n",
        "\n",
        "    def generate_code(self, prompt: str, model: str = \"openai/gpt-oss-120b\", use_groq: bool = True) -> str:\n",
        "        # Try Groq if requested and available\n",
        "        if use_groq and self.groq_api_key and Groq is not None:\n",
        "            try:\n",
        "                raw = self._call_groq(prompt, model=model)\n",
        "                return extract_code_only(raw)\n",
        "            except Exception as e:\n",
        "                st.warning(f\"Groq generation failed: {e}\")\n",
        "\n",
        "        # Fallback to OpenAI if configured\n",
        "        if self.openai_api_key and openai is not None:\n",
        "            try:\n",
        "                raw = self._call_openai(prompt)\n",
        "                return extract_code_only(raw)\n",
        "            except Exception as e:\n",
        "                st.warning(f\"OpenAI generation failed: {e}\")\n",
        "\n",
        "        # Deterministic fallback templates\n",
        "        return self._heuristic_fallback(prompt)\n",
        "\n",
        "    def _heuristic_fallback(self, prompt: str) -> str:\n",
        "        p = (prompt or \"\").lower()\n",
        "        if \"python\" in p or \".py\" in p:\n",
        "            return (\"def main():\\n    print('Fallback Python code. Provide an API key for real generation.')\\n\\nif __name__ == '__main__':\\n    main()\\n\")\n",
        "        if \"javascript\" in p or \".js\" in p:\n",
        "            return (\"function main(){\\n  console.log('Fallback JS code');\\n}\\nmain();\\n\")\n",
        "        if \"c++\" in p or \".cpp\" in p:\n",
        "            return (\"#include <iostream>\\nint main(){ std::cout << \\\"Fallback C++ code\\\" << std::endl; return 0; }\\n\")\n",
        "        if \"java\" in p or \".java\" in p:\n",
        "            return (\"public class Main{ public static void main(String[] args){ System.out.println(\\\"Fallback Java code\\\"); } }\\n\")\n",
        "        return \"# Fallback: no API available. Provide GROQ_API_KEY or OPENAI_API_KEY.\\n# Prompt:\\n# \" + prompt.replace('\\n', '\\n# ')\n",
        "\n",
        "# ---------------------------\n",
        "# CodeBLEU-like scorer (same proto as colab)\n",
        "# ---------------------------\n",
        "class CodeBLEUScorer:\n",
        "    def __init__(self, weights: Optional[Dict[str, float]] = None):\n",
        "        self.weights = weights or {\"ngram\": 0.4, \"ast\": 0.4, \"iden\": 0.2}\n",
        "\n",
        "    def _normalize(self, code: str) -> str:\n",
        "        return \"\\n\".join([ln.rstrip() for ln in (code or \"\").strip().splitlines()])\n",
        "\n",
        "    def _simple_tokens(self, code: str) -> List[str]:\n",
        "        return re.findall(r\"[A-Za-z_]\\w*|\\d+|==|!=|<=|>=|[\\(\\)\\{\\}\\[\\];,\\.\\+\\-\\*\\/]\", code)\n",
        "\n",
        "    def _python_ast_tokens(self, code: str) -> List[str]:\n",
        "        try:\n",
        "            tree = ast.parse(code)\n",
        "        except Exception:\n",
        "            return self._simple_tokens(code)\n",
        "        tokens: List[str] = []\n",
        "        class Visitor(ast.NodeVisitor):\n",
        "            def generic_visit(self, node):\n",
        "                tokens.append(type(node).__name__)\n",
        "                if isinstance(node, ast.Name):\n",
        "                    tokens.append(f\"Name:{node.id}\")\n",
        "                if isinstance(node, ast.arg):\n",
        "                    tokens.append(f\"Arg:{node.arg}\")\n",
        "                if isinstance(node, ast.FunctionDef):\n",
        "                    tokens.append(f\"Func:{node.name}\")\n",
        "                if isinstance(node, ast.ClassDef):\n",
        "                    tokens.append(f\"Class:{node.name}\")\n",
        "                ast.NodeVisitor.generic_visit(self, node)\n",
        "        Visitor().visit(tree)\n",
        "        return tokens\n",
        "\n",
        "    def _prec_rec_f1(self, hyp_tokens: List[str], ref_tokens: List[str]) -> Tuple[float, float, float]:\n",
        "        if not hyp_tokens or not ref_tokens:\n",
        "            return 0.0, 0.0, 0.0\n",
        "        from collections import Counter\n",
        "        ch, cr = Counter(hyp_tokens), Counter(ref_tokens)\n",
        "        inter = sum((ch & cr).values())\n",
        "        prec = inter / sum(ch.values()) if sum(ch.values()) else 0.0\n",
        "        rec = inter / sum(cr.values()) if sum(cr.values()) else 0.0\n",
        "        f1 = (2 * prec * rec / (prec + rec)) if (prec + rec) else 0.0\n",
        "        return prec, rec, f1\n",
        "\n",
        "    def _ngram_bleu(self, hyp: str, ref: str) -> float:\n",
        "        if sacrebleu:\n",
        "            try:\n",
        "                sc = sacrebleu.sentence_bleu(hyp, [ref])\n",
        "                return sc.score / 100.0\n",
        "            except Exception:\n",
        "                pass\n",
        "        h_tokens = self._simple_tokens(hyp)\n",
        "        r_tokens = self._simple_tokens(ref)\n",
        "        if not h_tokens or not r_tokens:\n",
        "            return 0.0\n",
        "        from collections import Counter\n",
        "        ch, cr = Counter(h_tokens), Counter(r_tokens)\n",
        "        inter = sum((ch & cr).values())\n",
        "        prec = inter / len(h_tokens)\n",
        "        bp = math.exp(1 - len(r_tokens) / len(h_tokens)) if len(h_tokens) < len(r_tokens) else 1.0\n",
        "        return prec * bp\n",
        "\n",
        "    def score(self, hypothesis: str, reference: str, language: str = \"python\") -> Dict[str, float]:\n",
        "        hyp = self._normalize(hypothesis)\n",
        "        ref = self._normalize(reference)\n",
        "        ngram = self._ngram_bleu(hyp, ref)\n",
        "        if language.lower().startswith(\"py\"):\n",
        "            hyp_ast = self._python_ast_tokens(hyp)\n",
        "            ref_ast = self._python_ast_tokens(ref)\n",
        "            _, _, ast_f1 = self._prec_rec_f1(hyp_ast, ref_ast)\n",
        "        else:\n",
        "            hyp_tok = self._simple_tokens(hyp)\n",
        "            ref_tok = self._simple_tokens(ref)\n",
        "            _, _, ast_f1 = self._prec_rec_f1(hyp_tok, ref_tok)\n",
        "        hyp_id = [t for t in self._simple_tokens(hyp) if re.match(r\"[A-Za-z_]\\w+$\", t)]\n",
        "        ref_id = [t for t in self._simple_tokens(ref) if re.match(r\"[A-Za-z_]\\w+$\", t)]\n",
        "        _, _, id_f1 = self._prec_rec_f1(hyp_id, ref_id)\n",
        "        combined = (self.weights[\"ngram\"] * ngram + self.weights[\"ast\"] * ast_f1 + self.weights[\"iden\"] * id_f1)\n",
        "        return {\n",
        "            \"ngram_bleu\": float(ngram),\n",
        "            \"ast_f1\": float(ast_f1),\n",
        "            \"identifier_f1\": float(id_f1),\n",
        "            \"combined_codebleu_like\": float(combined)\n",
        "        }\n",
        "\n",
        "# ---------------------------\n",
        "# Streamlit UI\n",
        "# ---------------------------\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"AI Code Generator + CodeBLEU\", layout=\"wide\")\n",
        "    st.title(\"AI Code Generator â€” Groq / OpenAI (Streamlit)\")\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.header(\"Configuration\")\n",
        "        groq_key_input = st.text_input(\"GROQ API Key\", value=os.getenv(\"GROQ_API_KEY\", \"\"), type=\"password\")\n",
        "        openai_key_input = st.text_input(\"OPENAI API Key\", value=os.getenv(\"OPENAI_API_KEY\", \"\"), type=\"password\")\n",
        "        model_choice = st.selectbox(\"Model\", options=[\"llama-3.1-70b-versatile\", \"llama-3.1-70b-specdec\", \"llama-3.1-8b-instant\", \"mixtral-8x7b-32768\", \"gemma2-9b-it\"], index=0)\n",
        "        use_groq = st.checkbox(\"Use Groq (if API key provided)\", value=True)\n",
        "        temp = st.slider(\"Sampling temperature\", min_value=0.0, max_value=1.0, value=0.0, step=0.05)\n",
        "        st.markdown(\"---\")\n",
        "        st.write(\"Notes:\")\n",
        "        st.write(\"â€¢ The agent aims to **return only code**. If model returns explanations they will be stripped.\")\n",
        "        st.write(\"â€¢ For Groq usage, install the Groq SDK and provide a valid key.\")\n",
        "\n",
        "    # prompt input\n",
        "    prompt = st.text_area(\"Prompt (request code only)\", height=160, placeholder=\"E.g. Write a Python function is_prime(n) -> bool; return only the Python file contents.\")\n",
        "\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "\n",
        "    with col1:\n",
        "        if st.button(\"Generate Code\"):\n",
        "            if not prompt.strip():\n",
        "                st.warning(\"Please enter a prompt requesting code.\")\n",
        "            else:\n",
        "                agent = CodeGenAgent(groq_api_key=groq_key_input or None, openai_api_key=openai_key_input or None, temperature=temp)\n",
        "                with st.spinner(\"Generating code...\"):\n",
        "                    code = agent.generate_code(prompt, model=model_choice, use_groq=use_groq)\n",
        "                # Display code only\n",
        "                st.subheader(\"Generated Code\")\n",
        "                language_hint = 'python' if 'python' in prompt.lower() or prompt.strip().startswith('def ') else ''\n",
        "                st.code(code, language=language_hint)\n",
        "\n",
        "                # Offer download\n",
        "                ext = '.py' if ('python' in prompt.lower() or prompt.lower().strip().startswith('def ') or 'import' in code) else '.txt'\n",
        "                st.download_button(\"Download generated code\", data=code, file_name=f\"generated_code{ext}\")\n",
        "\n",
        "                # store in session state for evaluation\n",
        "                st.session_state['last_generated_code'] = code\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Evaluation\")\n",
        "        st.write(\"Paste a reference implementation and click 'Evaluate' to compute CodeBLEU-like scores.\")\n",
        "        reference = st.text_area(\"Reference Code (for scoring)\", height=220, key='ref_input')\n",
        "        if st.button(\"Evaluate\"):\n",
        "            gen = st.session_state.get('last_generated_code', '').strip()\n",
        "            if not gen:\n",
        "                st.warning(\"No generated code available to evaluate. Generate code first.\")\n",
        "            elif not reference.strip():\n",
        "                st.warning(\"Please paste a reference implementation to compare against.\")\n",
        "            else:\n",
        "                scorer = CodeBLEUScorer()\n",
        "                with st.spinner(\"Scoring...\"):\n",
        "                    # Try detect language from prompt or reference\n",
        "                    lang = 'python'\n",
        "                    if reference.strip().startswith('import java') or 'class ' in reference and reference.strip().startswith('public'):\n",
        "                        lang = 'java'\n",
        "                    scores = scorer.score(gen, reference, language=lang)\n",
        "                st.metric(\"Combined CodeBLEU-like\", f\"{scores['combined_codebleu_like']:.4f}\")\n",
        "                st.write(scores)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.caption(\"This is a prototype evaluator and code generator. For production use, integrate official Groq SDK and a full CodeBLEU implementation.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4-POK5zOXQW",
        "outputId": "8ab05e88-4239-49d6-b30d-15b522d9908d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import re\n",
        "import ast\n",
        "import math\n",
        "import json\n",
        "import tempfile\n",
        "from typing import Optional, Dict, List, Tuple\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "# Optional third-party packages\n",
        "try:\n",
        "    import sacrebleu\n",
        "except Exception:\n",
        "    sacrebleu = None\n",
        "\n",
        "# Try Groq client import\n",
        "try:\n",
        "    from groq import Groq\n",
        "except Exception:\n",
        "    Groq = None\n",
        "\n",
        "# ---------------------------\n",
        "# Utilities\n",
        "# ---------------------------\n",
        "\n",
        "def extract_code_only(text: str) -> str:\n",
        "    \"\"\"Strip markdown fences and assistant lead-ins and return the largest code block if present.\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "\n",
        "    fences = re.findall(r\"```(?:[\\w+-]*)\\n(.*?)```\", text, re.DOTALL)\n",
        "    if fences:\n",
        "        fences_sorted = sorted(fences, key=lambda s: len(s), reverse=True)\n",
        "        return fences_sorted[0].strip()\n",
        "\n",
        "    lines = text.strip().splitlines()\n",
        "    leadin_pattern = re.compile(r\"^(here(?:'s| is)|sure|okay|note|the following)[:\\-â€”\\s]\", re.I)\n",
        "    while lines and leadin_pattern.match(lines[0].strip()):\n",
        "        lines.pop(0)\n",
        "    return \"\\n\".join(lines).strip()\n",
        "\n",
        "# ---------------------------\n",
        "# Code generation agent (Groq-only)\n",
        "# ---------------------------\n",
        "class CodeGenAgent:\n",
        "    def __init__(self, groq_api_key: Optional[str] = None, temperature: float = 0.0):\n",
        "        self.groq_api_key = groq_api_key or os.getenv(\"GROQ_API_KEY\")\n",
        "        self.temperature = temperature\n",
        "        self._groq_client = None\n",
        "\n",
        "    def _init_groq(self):\n",
        "        if Groq is None:\n",
        "            raise RuntimeError(\"Groq SDK not available. Install it (pip install groq) and restart the app.\")\n",
        "        if self._groq_client is None:\n",
        "            try:\n",
        "                # If user provided an API key, pass it to the client; otherwise rely on default environment/config.\n",
        "                self._groq_client = Groq(api_key=self.groq_api_key) if self.groq_api_key else Groq()\n",
        "            except Exception as e:\n",
        "                # Surface a clear error\n",
        "                raise RuntimeError(f\"Failed to initialize Groq client: {e}\")\n",
        "        return self._groq_client\n",
        "\n",
        "    def _call_groq(self, prompt: str, model: str, max_tokens: int = 2000) -> str:\n",
        "        client = self._init_groq()\n",
        "        # Adapt to common SDK shapes; try stable pattern first, then fallbacks\n",
        "        try:\n",
        "            resp = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You MUST return only the requested source code. No explanations, no markdown fences.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=self.temperature,\n",
        "                max_tokens=max_tokens,\n",
        "            )\n",
        "            return resp.choices[0].message.content\n",
        "        except Exception:\n",
        "            # Try alternate call shape\n",
        "            resp = client.create_chat_completion(model=model, messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You MUST return only the requested source code. No explanations, no markdown fences.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ], temperature=self.temperature)\n",
        "            return resp.choices[0].message.content\n",
        "\n",
        "    def generate_code(self, prompt: str, model: str = \"openai/gpt-oss-120b\", max_tokens: int = 2000) -> str:\n",
        "        \"\"\"Generate code using Groq only. If Groq is not configured or fails, raise a RuntimeError with guidance.\"\"\"\n",
        "        try:\n",
        "            raw = self._call_groq(prompt, model=model, max_tokens=max_tokens)\n",
        "            return extract_code_only(raw)\n",
        "        except Exception as e:\n",
        "            # Give a clear error so the Streamlit UI can surface it\n",
        "            raise RuntimeError(f\"Groq generation failed: {e}\\nMake sure GROQ_API_KEY is set and the Groq SDK is installed.\")\n",
        "\n",
        "    def _heuristic_fallback(self, prompt: str) -> str:\n",
        "        # Keep a small deterministic fallback in case the caller prefers to not raise.\n",
        "        p = (prompt or \"\").lower()\n",
        "        if \"python\" in p or \".py\" in p:\n",
        "            return (\n",
        "                \"def main():\\n    print('Fallback Python code. Provide a GROQ_API_KEY for real generation.')\\n\\nif __name__ == '__main__':\\n    main()\\n\"\n",
        "            )\n",
        "        if \"javascript\" in p or \".js\" in p:\n",
        "            return (\"function main(){\\n  console.log('Fallback JS code');\\n}\\nmain();\\n\")\n",
        "        return \"# Fallback: no GROQ available. Provide GROQ_API_KEY.\\n# Prompt:\\n# \" + prompt.replace('\\n', '\\n# ')\n",
        "\n",
        "# ---------------------------\n",
        "# CodeBLEU-like scorer (same proto as colab)\n",
        "# ---------------------------\n",
        "class CodeBLEUScorer:\n",
        "    def __init__(self, weights: Optional[Dict[str, float]] = None):\n",
        "        self.weights = weights or {\"ngram\": 0.4, \"ast\": 0.4, \"iden\": 0.2}\n",
        "\n",
        "    def _normalize(self, code: str) -> str:\n",
        "        return \"\\n\".join([ln.rstrip() for ln in (code or \"\").strip().splitlines()])\n",
        "\n",
        "    def _simple_tokens(self, code: str) -> List[str]:\n",
        "        return re.findall(r\"[A-Za-z_]\\w*|\\d+|==|!=|<=|>=|[\\(\\)\\{\\}\\[\\];,\\.\\+\\-\\*\\/]\", code)\n",
        "\n",
        "    def _python_ast_tokens(self, code: str) -> List[str]:\n",
        "        try:\n",
        "            tree = ast.parse(code)\n",
        "        except Exception:\n",
        "            return self._simple_tokens(code)\n",
        "        tokens: List[str] = []\n",
        "        class Visitor(ast.NodeVisitor):\n",
        "            def generic_visit(self, node):\n",
        "                tokens.append(type(node).__name__)\n",
        "                if isinstance(node, ast.Name):\n",
        "                    tokens.append(f\"Name:{node.id}\")\n",
        "                if isinstance(node, ast.arg):\n",
        "                    tokens.append(f\"Arg:{node.arg}\")\n",
        "                if isinstance(node, ast.FunctionDef):\n",
        "                    tokens.append(f\"Func:{node.name}\")\n",
        "                if isinstance(node, ast.ClassDef):\n",
        "                    tokens.append(f\"Class:{node.name}\")\n",
        "                ast.NodeVisitor.generic_visit(self, node)\n",
        "        Visitor().visit(tree)\n",
        "        return tokens\n",
        "\n",
        "    def _prec_rec_f1(self, hyp_tokens: List[str], ref_tokens: List[str]) -> Tuple[float, float, float]:\n",
        "        if not hyp_tokens or not ref_tokens:\n",
        "            return 0.0, 0.0, 0.0\n",
        "        from collections import Counter\n",
        "        ch, cr = Counter(hyp_tokens), Counter(ref_tokens)\n",
        "        inter = sum((ch & cr).values())\n",
        "        prec = inter / sum(ch.values()) if sum(ch.values()) else 0.0\n",
        "        rec = inter / sum(cr.values()) if sum(cr.values()) else 0.0\n",
        "        f1 = (2 * prec * rec / (prec + rec)) if (prec + rec) else 0.0\n",
        "        return prec, rec, f1\n",
        "\n",
        "    def _ngram_bleu(self, hyp: str, ref: str) -> float:\n",
        "        if sacrebleu:\n",
        "            try:\n",
        "                sc = sacrebleu.sentence_bleu(hyp, [ref])\n",
        "                return sc.score / 100.0\n",
        "            except Exception:\n",
        "                pass\n",
        "        h_tokens = self._simple_tokens(hyp)\n",
        "        r_tokens = self._simple_tokens(ref)\n",
        "        if not h_tokens or not r_tokens:\n",
        "            return 0.0\n",
        "        from collections import Counter\n",
        "        ch, cr = Counter(h_tokens), Counter(r_tokens)\n",
        "        inter = sum((ch & cr).values())\n",
        "        prec = inter / len(h_tokens)\n",
        "        bp = math.exp(1 - len(r_tokens) / len(h_tokens)) if len(h_tokens) < len(r_tokens) else 1.0\n",
        "        return prec * bp\n",
        "\n",
        "    def score(self, hypothesis: str, reference: str, language: str = \"python\") -> Dict[str, float]:\n",
        "        hyp = self._normalize(hypothesis)\n",
        "        ref = self._normalize(reference)\n",
        "        ngram = self._ngram_bleu(hyp, ref)\n",
        "        if language.lower().startswith(\"py\"):\n",
        "            hyp_ast = self._python_ast_tokens(hyp)\n",
        "            ref_ast = self._python_ast_tokens(ref)\n",
        "            _, _, ast_f1 = self._prec_rec_f1(hyp_ast, ref_ast)\n",
        "        else:\n",
        "            hyp_tok = self._simple_tokens(hyp)\n",
        "            ref_tok = self._simple_tokens(ref)\n",
        "            _, _, ast_f1 = self._prec_rec_f1(hyp_tok, ref_tok)\n",
        "        hyp_id = [t for t in self._simple_tokens(hyp) if re.match(r\"[A-Za-z_]\\w+$\", t)]\n",
        "        ref_id = [t for t in self._simple_tokens(ref) if re.match(r\"[A-Za-z_]\\w+$\", t)]\n",
        "        _, _, id_f1 = self._prec_rec_f1(hyp_id, ref_id)\n",
        "        combined = (self.weights[\"ngram\"] * ngram + self.weights[\"ast\"] * ast_f1 + self.weights[\"iden\"] * id_f1)\n",
        "        return {\n",
        "            \"ngram_bleu\": float(ngram),\n",
        "            \"ast_f1\": float(ast_f1),\n",
        "            \"identifier_f1\": float(id_f1),\n",
        "            \"combined_codebleu_like\": float(combined)\n",
        "        }\n",
        "\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"AI Code Generator + CodeBLEU (Groq-only)\", layout=\"wide\")\n",
        "    st.title(\"AI Code Generator â€” Groq (Streamlit)\")\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.header(\"Configuration\")\n",
        "        groq_key_input = st.text_input(\"GROQ API Key\", value=os.getenv(\"GROQ_API_KEY\", \"\"), type=\"password\")\n",
        "        model_choice = st.selectbox(\"Model\", options=[\"openai/gpt-oss-120b\", \"llama-3.1-70b-specdec\", \"llama-3.1-8b-instant\", \"mixtral-8x7b-32768\", \"gemma2-9b-it\"], index=0)\n",
        "        temp = st.slider(\"Sampling temperature\", min_value=0.0, max_value=1.0, value=0.0, step=0.05)\n",
        "        st.markdown(\"---\")\n",
        "        st.write(\"Notes:\")\n",
        "        st.write(\"â€¢ This app uses Groq only. Install the Groq SDK (pip install groq) and provide GROQ_API_KEY.\")\n",
        "        st.write(\"â€¢ The agent will request code-only responses from the model; the app strips extra text if present.\")\n",
        "\n",
        "    # prompt input\n",
        "    prompt = st.text_area(\"Prompt (request code only)\", height=160, placeholder=\"E.g. Write a Python function is_prime(n) -> bool; return only the Python file contents.\")\n",
        "\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "\n",
        "    with col1:\n",
        "        if st.button(\"Generate Code\"):\n",
        "            if not prompt.strip():\n",
        "                st.warning(\"Please enter a prompt requesting code.\")\n",
        "            else:\n",
        "                agent = CodeGenAgent(groq_api_key=groq_key_input or None, temperature=temp)\n",
        "                try:\n",
        "                    with st.spinner(\"Generating code via Groq...\"):\n",
        "                        code = agent.generate_code(prompt, model=model_choice)\n",
        "                except Exception as e:\n",
        "                    st.error(str(e))\n",
        "                    # Offer a small deterministic fallback so user can continue testing locally\n",
        "                    code = agent._heuristic_fallback(prompt)\n",
        "\n",
        "                # Display code only\n",
        "                st.subheader(\"Generated Code\")\n",
        "                language_hint = 'python' if 'python' in prompt.lower() or prompt.strip().startswith('def ') else ''\n",
        "                st.code(code, language=language_hint)\n",
        "\n",
        "                # Offer download\n",
        "                ext = '.py' if ('python' in prompt.lower() or prompt.lower().strip().startswith('def ') or 'import' in code) else '.txt'\n",
        "                st.download_button(\"Download generated code\", data=code, file_name=f\"generated_code{ext}\")\n",
        "\n",
        "                # store in session state for evaluation\n",
        "                st.session_state['last_generated_code'] = code\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"Evaluation\")\n",
        "        st.write(\"Paste a reference implementation and click 'Evaluate' to compute CodeBLEU-like scores.\")\n",
        "        reference = st.text_area(\"Reference Code (for scoring)\", height=220, key='ref_input')\n",
        "        if st.button(\"Evaluate\"):\n",
        "            gen = st.session_state.get('last_generated_code', '').strip()\n",
        "            if not gen:\n",
        "                st.warning(\"No generated code available to evaluate. Generate code first.\")\n",
        "            elif not reference.strip():\n",
        "                st.warning(\"Please paste a reference implementation to compare against.\")\n",
        "            else:\n",
        "                scorer = CodeBLEUScorer()\n",
        "                with st.spinner(\"Scoring...\"):\n",
        "                    # Try detect language from reference\n",
        "                    lang = 'python'\n",
        "                    if reference.strip().startswith('import java') or 'class ' in reference and reference.strip().startswith('public'):\n",
        "                        lang = 'java'\n",
        "                    scores = scorer.score(gen, reference, language=lang)\n",
        "                st.metric(\"Combined CodeBLEU-like\", f\"{scores['combined_codebleu_like']:.4f}\")\n",
        "                st.write(scores)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.caption(\"Groq-only prototype evaluator and code generator. For production use, configure the Groq client and a full CodeBLEU implementation.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xf8AXwwSzaw",
        "outputId": "a4174e2d-9ef0-4f48-ae93-27d3d1cb91e3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mmKU0GqTOyr",
        "outputId": "da733e02-cbd8-4bcc-993d-5b295a2ccdc8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/136.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m136.0/136.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    }
  ]
}